---
title: "Question 1: Sampling algorithms for a triangle distribution"
output:
  pdf_document: 
    keep_tex: true
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
tables: true
header-includes:
 \usepackage{float}
 \setlength{\textfloatsep}{0pt}

---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r include=FALSE}
library(ggplot2)
library(gridExtra)
```

```{r include=FALSE}
triangleDensity <- function(x) {
  ifelse(
    (x < -1) | (x > 1),
    0,
    ifelse((-1 <= x) & (x <= 0), x + 1, 1 - x)
  )
}

rtriang <- function(n, scale = 1) (1 - sqrt(1 - runif(n))) * scale
```


## Rejection sampling

Consider the triangle-shape density given by

$$ p(x) =
\begin{cases} 
      0 & |x| > 1 \\
      x + 1 & -1 \leq x \leq 0 \\
      1 - x & 0 < x \leq 1
   \end{cases}
$$
We are interested in generating draws of a random variable $X$ with this density
using the rejection sampling method. This method makes use of another random variable $Y$ whose probability density $g(y)$ is similar to the probability
density of $X$, $p(x)$, but easier to sample from. Notice the support of the target density $p(x)$ must be contained in the support of $g(y)$, also called the **envelope density**. A natural envelope choice for distributions with finite support is the uniform distribution. Since $X$ goes from $-1$ to $1$, we make $Y \sim U(-1, 1)$, so that

$$
g(y) =
\begin{cases} 
      \frac{1}{2} & |y| \leq 1 \\
      0 & \text{otherwise}\\
   \end{cases}
$$ 

To complete the rejection sampling procedure, $g(y)$ can be scaled to majorize
$p(x)$ using some constant $c$; that is, $cg(x) \geq p(x)$ for all $x$. Since $p(x)$ reaches its maximum value of $1$ at $x=1$ and $g(x) = \frac{1}{2}$, $c\frac{1}{2} \geq 1 \implies c \geq 2$. An histogram of the accepted deviates is shown below.


```{r include=FALSE}
y <- runif(10000, -1 , 1)  # Generate y from the majorizing (envelope) distribution.
u <- runif(10000)          # Generate u from a uniform (0, 1) distribution.
x <- na.omit(ifelse(u <= triangleDensity(y), y, NA))
```

```{r fig.height=2, fig.width=2, fig.align="center", fig.cap="Histogram of accepted values. The red curve shows the target (true) density.", echo=FALSE}
par(mar = c(3, 3, 1, 1))  # Adjust margins: c(bottom, left, top, right)
hist(x, probability = TRUE, breaks = 20, col = "skyblue", main = "")
curve(triangleDensity(x), add = TRUE, col = "red", lwd = 2)
xRejectionSampling <- x
```


## Composition sampling

Let $Y$ be a random variable following the triangle density from lecture 3.
Namely, 

$$ p(y) =
\begin{cases} 
      2 - 2y & 0 \leq y \leq 1 \\
      0 & \text{otherwise} \\
   \end{cases}
$$
Its cumulative distribution function $F$ is

$$ F(y) =
\begin{cases} 
      0 & y < 0 \\
      2y - y^2 & 0 \leq y \leq 1 \\
      1 & y > 1 \\
   \end{cases}
$$
Furthermore, the inverse CDF (quantile function) is given by 
$F^{-1}(p) = 1 - \sqrt{1 - p}$ which allows sampling from $Y$ using the
transformation $Y = F^{-1}(U)$ where $U \sim U(0, 1)$. This method is known as 
the *inverse* CDF technique. Now, consider a new random variable $X$ given by the mixture of $-Y$ and $Y$. 
A random generator of $X$ values can be obtained using the *composition sampling* 
technique where samples from $Y$ and $-Y$ are generated by the inverse CDF method.
The following histograms summarize this procedure for different combinations 
of mixing probabilities.


```{r fig.height=2, fig.width=6, fig.align="center", fig.cap="Histograms for different mixing probabilities.", echo=FALSE}
# Function to create a histogram
plot_histogram <- function(data) {
  ggplot(data.frame(x = data), aes(x)) +
    geom_histogram(aes(y = after_stat(density)), bins = 20, fill = "skyblue", alpha = 0.7) +
    theme_minimal() +
    theme(axis.title = element_blank(), axis.text = element_text(size = 12))
}

n <- 10000

# Case 1: p(Y) = 0.3, p(-Y) = 0.7
prob <- c(.3, .7)
scalers <- sample(c(1, -1), size = n, replace = TRUE, prob = prob)
x1 <- rtriang(n, scalers)

# Case 2: p(Y) = 0.5, p(-Y) = 0.5
prob <- c(.5, .5)
scalers <- sample(c(1, -1), size = n, replace = TRUE, prob = prob)
x2 <- rtriang(n, scalers)
xCompositionSampling <- x2

# Case 3: p(Y) = 0.7, p(-Y) = 0.3
prob <- c(.7, .3)
scalers <- sample(c(1, -1), size = n, replace = TRUE, prob = prob)
x3 <- rtriang(n, scalers)

# Create the histograms
par(mfrow = c(1, 3))
hist(x1, probability = TRUE, breaks = 20, col = "skyblue", main = "")
hist(x2, probability = TRUE, breaks = 20, col = "skyblue", main = "")
hist(x3, probability = TRUE, breaks = 20, col = "skyblue", main = "")
par(mfrow = c(1, 1))
```

Notice the histogram corresponding to $X$ is the one having equal mixing probabilities
which is shown in the center of the figure.


## Triangle distribution as the sum (or difference) of uniforms

Sums or differences of two independent uniformly distributed variables can also 
follow a triangular distribution. The histogram below illustrates this by 
showing the distribution of $U_1 - U_2$, where $U_1$ and $U_2$ are independent 
random variables following a standard uniform distribution.

```{r fig.height=2, fig.width=2, fig.align="center", fig.cap="Triangle distribution obtained by sampling from the difference of uniform random variables.", echo=FALSE}
par(mar = c(3, 3, 1, 1))  # Adjust margins: c(bottom, left, top, right)
n <- 10000
u1 <- runif(n)
u2 <- runif(n)
xDifference <- u1 - u2
hist(xDifference, probability = TRUE, breaks = 20, col = "skyblue", main = "")
```

## Which of the three methods do you prefer?

All three methods—rejection sampling, composition sampling, and the difference of uniforms—are valid for generating random draws from $X$. However, their efficiency and practicality vary depending on the context.

For this specific case, I would avoid **rejection sampling** because it involves discarding a significant number of proposed values. Instead, I prefer the **composition sampling approach**, as it leverages the well-defined inverse CDF of $Y$ to 
generate samples efficiently. The ability to construct $X$ as a mixture of $Y$ 
and $-Y$ ensures that every generated sample is accepted, eliminating wasted computations.

The **difference of uniforms method** is a nice theoretical result (Irwin–Hall distribution); however, it is very much specialized for this situation
and does not generalize to other distributions.

## Variance of X

Finally, the following table shows the variance for each of the methods.

```{r echo=FALSE}
varDf <- data.frame(
  RejectionSampling = var(xRejectionSampling),
  CompositionSampling = var(xCompositionSampling),
  UniformDifference = var(xDifference)
)

knitr::kable(
  varDf,
  row.names = FALSE,
  caption = "Variance for each of the three methods."
)
```

## Appendix

```r
# TASK A
# ------

triangleDensity <- function(x) {
  ifelse(
    (x < -1) | (x > 1),
    0,
    ifelse((-1 <= x) & (x <= 0), x + 1, 1 - x)
  )
}


# The value of `c` by which we scale the uniform density should be as small
# as possible to minimize the frequency with which we reject the candidate 
# points. This requires determination of the maximum value of the triangle 
# density, which we can compute easily by evaluating at 0.
c <- triangleDensity(0)

# To generate the deviates from the triangle using the uniform majorizing 
# density (i.e., the envelope), we write the following statements.
y <- runif(10000, -1 , 1)  # Generate y from the majorizing (envelope) distribution.
u <- runif(10000)          # Generate u from a uniform (0, 1) distribution.
x <- na.omit(ifelse(u <= triangleDensity(y), y, NA))


# TASK B
# ------

# Let Y be a random variable following the triangle distribution from lecture 3
# with CDF F and F^-1 = 1 - sqrt(1 - y). Then, a sample from this distribution
# can be obtained as follows.
rtriang <- function(n, scale = 1) (1 - sqrt(1 - runif(n))) * scale

# Next, we can create a new random variable X using composition sampling
# based on Y and -Y.
n <- 10000
prob <- c(.5 .5)
scalers <- sample(c(1, -1), size = n, replace = TRUE, prob = prob)
x <- rtriang(n, scalers)


# TASK C
# ------

n <- 10000
u1 <- runif(n)
u2 <- runif(n)
x <- u1 - u2
```
